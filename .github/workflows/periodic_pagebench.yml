name: Periodic pagebench performance test on dedicated EC2 machine in eu-central-1 region

on:
  schedule:
    # * is a special character in YAML so you have to quote this string
    #        ┌───────────── minute (0 - 59)
    #        │   ┌───────────── hour (0 - 23)
    #        │   │ ┌───────────── day of the month (1 - 31)
    #        │   │ │ ┌───────────── month (1 - 12 or JAN-DEC)
    #        │   │ │ │ ┌───────────── day of the week (0 - 6 or SUN-SAT)
    - cron: '0 */3 * * *' # Runs every 3 hours
  workflow_dispatch: # Allows manual triggering of the workflow
    inputs:
      commit_hash:
        type: string
        description: 'The long neon repo commit hash for the system under test (pageserver) to be tested.'
        required: false
        default: ''

defaults:
  run:
    shell: bash -euo pipefail {0}

concurrency:
  group: ${{ github.workflow }}
  cancel-in-progress: false

permissions:
  contents: read

jobs:
  run_periodic_pagebench_test:
    permissions:
      id-token: write # aws-actions/configure-aws-credentials
      statuses: write
      contents: write
      pull-requests: write
    runs-on: [ self-hosted, unit-perf ]
    container:
      image: ghcr.io/neondatabase/build-tools:pinned-bookworm
      credentials:
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
      options: --init
    timeout-minutes: 360  # Set the timeout to 6 hours
    env:
      RUN_ID: ${{ github.run_id }}
    steps:
    # we don't need the neon source code because we run everything remotely
    # however we still need the local github actions to run the allure step below
    - name: Harden the runner (Audit all outbound calls)
      uses: step-security/harden-runner@4d991eb9b905ef189e4c376166672c3f2f230481 # v2.11.0
      with:
        egress-policy: audit

    - uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2

    - uses: aws-actions/configure-aws-credentials@e3dd6a429d7300a6a4c196c26e071d42e0343502 # v4.0.2
      with:
        aws-region: eu-central-1
        role-to-assume: ${{ vars.DEV_AWS_OIDC_ROLE_ARN }}
        role-duration-seconds: 18000 # max 5 hours (needed in case commit hash is still being built)
    - name: Determine commit hash
      env:
        INPUT_COMMIT_HASH: ${{ github.event.inputs.commit_hash }}
      run: |
        if [ -z "$INPUT_COMMIT_HASH" ]; then
          echo "COMMIT_HASH=$(curl -s https://api.github.com/repos/neondatabase/neon/commits/main | jq -r '.sha')" >> $GITHUB_ENV
          echo "COMMIT_HASH_TYPE=latest" >> $GITHUB_ENV
        else
          echo "COMMIT_HASH=$INPUT_COMMIT_HASH" >> $GITHUB_ENV
          echo "COMMIT_HASH_TYPE=manual" >> $GITHUB_ENV
        fi

    # does not reuse ./.github/actions/download because we need to download the artifact for the given commit hash
    # example artifact
    # s3://neon-github-public-dev/artifacts/48b870bc078bd2c450eb7b468e743b9c118549bf/15036827400/1/neon-Linux-X64-release-artifact.tar.zst /instance_store/artifacts/neon-Linux-release-artifact.tar.zst
    - name: Determine artifact S3_KEY for commit hash ${COMMIT_HASH} and download and extract artifact
      id: artifact_prefix
      shell: bash -euxo pipefail {0}
      env:
        ARCHIVE: /tmp/downloads/neon-${{ runner.os }}-${{ runner.arch }}-release-artifact.tar.zst
        TARGET: /tmp/neon
        COMMIT_HASH: ${{ env.COMMIT_HASH }}
        COMMIT_HASH_TYPE: ${{ env.COMMIT_HASH_TYPE }}
      run: |
        attempt=0
        max_attempts=24 # 5 minutes * 24 = 2 hours

        while [ $attempt -lt $max_attempts ]; do
          set +e # the following command will fail until the artifacts are available
          S3_KEY=$(aws s3api list-objects-v2 --bucket neon-github-public-dev --prefix artifacts/$COMMIT_HASH/ | jq -r '.Contents[]?.Key' | grep neon-${{ runner.os }}-${{ runner.arch }}-release-artifact.tar.zst | sort --version-sort | tail -1)
          set -e

          if [ ! -z "$S3_KEY" ]; then
            echo "Artifact found: $S3_KEY"
            echo "S3_KEY=$S3_KEY" >> $GITHUB_ENV
            break
          fi
          
          # Increment attempt counter and sleep for 5 minutes
          attempt=$((attempt + 1))
          echo "Attempt $attempt of $max_attempts to find artifacts in S3 bucket s3://neon-github-public-dev/artifacts/$COMMIT_HASH failed. Retrying in 5 minutes..."
          sleep 300 # Sleep for 5 minutes
        done

        if [ -z "$S3_KEY" ]; then
          echo "Error: artifact not found in S3 bucket s3://neon-github-public-dev/artifacts/$COMMIT_HASH" after 2 hours
        else
          mkdir -p $(dirname $ARCHIVE)
          trap 'rm -rf $ARCHIVE ${TARGET}' EXIT
          time aws s3 cp --only-show-errors s3://neon-github-public-dev/${S3_KEY} ${ARCHIVE}
          mkdir -p ${TARGET}
          time tar -xf ${ARCHIVE} -C ${TARGET}
          rm -f ${ARCHIVE}
        fi
       
    - name: Cleanup Test Resources
      if: always()
      shell: bash -euxo pipefail {0}
      env:
        ARCHIVE: /tmp/downloads/neon-${{ runner.os }}-${{ runner.arch }}-release-artifact.tar.zst
        TARGET: /tmp/neon
      run: |
        # Cleanup the test resources
        if [ -d "${TARGET}" ]; then
          rm -rf ${TARGET}
        fi
        rm -f $(dirname $ARCHIVE)

